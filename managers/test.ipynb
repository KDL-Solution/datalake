{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff2c7bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duck db\n",
    "import os\n",
    "os.chdir(\"/home/kai/workspace/DeepDocs_Project/datalake/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ce8596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from client import DuckDBClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65e086a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = DuckDBClient(\n",
    "    database_path=\"/mnt/AI_NAS/datalake/db/catalog.duckdb\",\n",
    "    read_only=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb806c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.create_table_from_parquet(\n",
    "    \"test\",\n",
    "    \"/mnt/AI_NAS/datalake/**/*.parquet\",\n",
    "    hive_partitioning=True,\n",
    "    union_by_name=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a171358",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = DuckDBClient(\n",
    "    database_path=\"/mnt/AI_NAS/datalake/db/catalog.duckdb\",\n",
    "    read_only=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7fead3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<client.src.core.duckdb_client.DuckDBClient at 0x7f6e50d55310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8471f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk('/home/kai/workspace/DeepDocs_Project/datalake/downloads/export_4999_items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = conn.execute(\"\"\"\n",
    "    SELECT * FROM read_parquet('/mnt/AI_NAS/datalake/catalog/provider=*/dataset=*/task=*/variant=*/**/data.parquet', union_by_name=True)\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14136466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:9064/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e2d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print model\n",
    "\n",
    "models = client.models.list()\n",
    "for model in models.data:\n",
    "    print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def base64_encode(\n",
    "    image_path,\n",
    "):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        image_bytes = image_file.read()\n",
    "    return base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "image_path = \"/home/kai/workspace/DeepDocs_Project/datalake/managers/test4.jpg\"\n",
    "base64_image = base64_encode(\n",
    "    image_path,\n",
    ")\n",
    "    \n",
    "messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Extract all layout elements. Reading order does not matter.\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "start_time = time.time()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"adapter\",\n",
    "    messages=messages,\n",
    "    temperature=0.0,\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "tokens = completion.usage.total_tokens\n",
    "tokens_per_second = tokens / elapsed_time\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Tokens per second: {tokens_per_second:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f6128",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a319ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a1afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen2VLImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffcf3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Qwen2VLImageProcessor.from_pretrained(\"/mnt/AI_NAS/AI_MODEL/checkpoints/Qwen/Qwen2.5-VL-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c67b5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image = Image.open(image_path)\n",
    "inputs = processor(\n",
    "    images=[image],\n",
    "    return_tensors=\"np\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97cf922",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['pixel_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41795c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import json\n",
    "image = Image.open(image_path)\n",
    "draw = ImageDraw.Draw(image)\n",
    "target = json.loads(result)\n",
    "\n",
    "for item in target:\n",
    "    class_ = item.get(\"type\", \"unknown\")\n",
    "    bbox = item.get(\"bbox\", [0, 0, 0, 0])\n",
    "    x0, y0, x1, y1 = bbox\n",
    "    x0, y0, x1, y1 = int(x0), int(y0), int(x1), int(y1)\n",
    "    # \n",
    "    x0 -= 14\n",
    "    x1 += 14\n",
    "    y0 -= 14\n",
    "    y1 += 14\n",
    "    draw.rectangle([x0, y0, x1, y1], outline=\"red\", width=2)\n",
    "    draw.text((x0, y0), class_, fill=\"red\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/kai/workspace/DeepDocs_Project/datalake\")\n",
    "from client.src.core.duckdb_client import DuckDBClient\n",
    "from datalake_client import DatalakeClient\n",
    "from datasets import Dataset, load_from_disk\n",
    "import os\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# datalake_client.py\n",
    "manager = DatalakeClient(\n",
    "    nas_api_url=\"http://192.168.20.62:8091\",\n",
    "    num_proc=32)\n",
    "duckdb = DuckDBClient(\n",
    "    database_path=manager.base_path / \"catalog.duckdb\",\n",
    "    read_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e1f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.show_nas_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bebf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_db = duckdb.retrieve_partitions()\n",
    "all_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f901a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 30\n",
    "provider = all_db.iloc[index]['provider']\n",
    "dataset = all_db.iloc[index]['dataset']\n",
    "print(f\"provider: {provider}, dataset: {dataset}\")\n",
    "db = duckdb.retrieve_with_existing_cols(\n",
    "    providers=provider,\n",
    "    datasets=dataset,\n",
    ")\n",
    "\n",
    "print(\"db:\")\n",
    "\n",
    "db = db.drop(columns=['provider', 'dataset', 'task', 'variant'], errors='ignore')\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659bab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"kie\"\n",
    "variant = \"base_kie\"\n",
    "meta = {\n",
    "    \"lang\": \"ko\",\n",
    "    \"src\": \"real\",\n",
    "}\n",
    "staging_dir, job_id = manager.upload_task_data(\n",
    "    data_file=db,\n",
    "    provider=provider,\n",
    "    dataset=dataset,\n",
    "    task=task,\n",
    "    variant=variant,\n",
    "    dataset_description=\"설명을 변경해주세요.\",\n",
    "    overwrite=False,\n",
    "    meta=meta,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11160f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.trigger_nas_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a1509",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.wait_for_job_completion(\"job_20250617_060301_119\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2635a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = []\n",
    "for parquet_path in tqdm(parquets):\n",
    "    try:\n",
    "        db = Dataset.from_parquet(parquet_path)\n",
    "        if \"image_path\" in db.column_names:\n",
    "            db = db.map(lambda x: {\"image_path\": apply_image_path(x)})\n",
    "        # if db에 date가 없을경우\n",
    "        if \"date\" not in db.column_names:\n",
    "            db = db.map(lambda x: {\"date\": datetime.now().strftime(\"%Y-%m-%d\")})\n",
    "        \n",
    "        provider, dataset, task, variant, *etc = parquet_path.replace(\"/mnt/AI_NAS/datalake/catalog/\",\"\").split(\"/\")[:-1]\n",
    "        provider = provider.replace(\"provider=\", \"\")\n",
    "        dataset = dataset.replace(\"dataset=\", \"\")\n",
    "        task = task.replace(\"task=\", \"\")\n",
    "        variant = variant.replace(\"variant=\", \"\")\n",
    "        meta = {}\n",
    "        for et in etc:\n",
    "            key, value = et.split(\"=\")\n",
    "            meta[key] = value\n",
    "        if \"table\" in variant:\n",
    "            meta[\"mod\"] = \"table\"        \n",
    "\n",
    "        print(f\"provider: {provider}, dataset: {dataset}, task: {task}, variant: {variant}, meta: {meta}\")\n",
    "        temp_path = f\"./temp/{provider}/{dataset}/{task}/{variant}\"\n",
    "        db.save_to_disk(temp_path)\n",
    "        staging_dir, job_id = manager.upload_raw_data(\n",
    "            data_file=temp_path,\n",
    "            provider=provider,\n",
    "            dataset=dataset,\n",
    "            dataset_description=\"설명을 변경해주세요.\",\n",
    "            original_source=\"링크를 입력해주세요.\",\n",
    "            overwrite=False,\n",
    "        )\n",
    "        # manager.trigger_nas_processing()\n",
    "        # manager.wait_for_job_completion(job_id, timeout=1280000)\n",
    "        # uploaded_db = Dataset.from_parquet(f\"/mnt/AI_NAS/datalake/catalog/provider={provider}/dataset={dataset}/task=raw/variant=*/data.parquet\")\n",
    "        # uploaded_db.save_to_disk(temp_path)\n",
    "        # manager.upload_task_data(\n",
    "        #     data_file=temp_path,\n",
    "        #     provider=provider,\n",
    "        #     dataset=dataset,\n",
    "        #     task=task,\n",
    "        #     variant=variant,\n",
    "        #     dataset_description=\"설명을 변경해주세요.\",\n",
    "        #     original_source=\"링크를 입력해주세요.\",\n",
    "        #     **meta,  # unpack meta dictionary\n",
    "        # )\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {parquet_path}: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "        error_list.append({\n",
    "            \"parquet_path\": parquet_path,\n",
    "            \"error\": str(e)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa90d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e00dba",
   "metadata": {},
   "source": [
    "parquets = glob(\"/mnt/AI_NAS/datalake/catalog/provider=*/dataset=*/task=*/**/*.parquet\", recursive=True)\n",
    "all_parquets = parquets.copy()\n",
    "print(len(parquets))\n",
    "parquets = [p for p in parquets if \"synthtabnet\" not in p]\n",
    "parquets = [p for p in parquets if \"pubtables\" not in p]\n",
    "parquets = [p for p in parquets if \"pubtabnet\" not in p]\n",
    "parquets = [p for p in parquets if \"fintabnet\" not in p]\n",
    "parquets = [p for p in parquets if \"vis_qa\" not in p]\n",
    "parquets = [p for p in parquets if \"table_image_text_pair\" not in p]\n",
    "parquets = [p for p in parquets if \"diverse_ocr_word\" not in p]\n",
    "parquets = [p for p in parquets if \"diverse_ocr_char\" not in p]\n",
    "parquets = [p for p in parquets if \"tourism_food_menu_board\" not in p]\n",
    "print(len(parquets))\n",
    "\n",
    "# 역으로 구하기\n",
    "\n",
    "reverse_parquets = [p for p in all_parquets if p not in parquets]\n",
    "reverse_parquets = [p for p in all_parquets if p not in parquets]\n",
    "parquets = reverse_parquets.copy()\n",
    "parquets = [p for p in parquets if \"pubtabnet_otsl\" not in p]\n",
    "parquets = [p for p in parquets if \"tourism_food_menu_board\" not in p]\n",
    "parquets = [p for p in parquets if \"table_image_text_pair\" not in p]\n",
    "print(len(parquets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17b468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_image_path(row):\n",
    "    if row['image_path']:\n",
    "        path = f\"/mnt/AI_NAS/datalake/{row['image_path']}\"\n",
    "        # check path exists\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "        raise FileNotFoundError(f\"Image path does not exist: {path}\")\n",
    "    return None\n",
    "error_list = []\n",
    "for parquet_path in tqdm(parquets):\n",
    "    try:\n",
    "        db = Dataset.from_parquet(parquet_path)\n",
    "        if \"image_path\" in db.column_names:\n",
    "            db = db.map(lambda x: {\"image_path\": apply_image_path(x)})\n",
    "        # if db에 date가 없을경우\n",
    "        if \"date\" not in db.column_names:\n",
    "            db = db.map(lambda x: {\"date\": datetime.now().strftime(\"%Y-%m-%d\")})\n",
    "        \n",
    "        provider, dataset, task, variant, *etc = parquet_path.replace(\"/mnt/AI_NAS/datalake/catalog/\",\"\").split(\"/\")[:-1]\n",
    "        provider = provider.replace(\"provider=\", \"\")\n",
    "        dataset = dataset.replace(\"dataset=\", \"\")\n",
    "        task = task.replace(\"task=\", \"\")\n",
    "        variant = variant.replace(\"variant=\", \"\")\n",
    "        meta = {}\n",
    "        for et in etc:\n",
    "            key, value = et.split(\"=\")\n",
    "            meta[key] = value\n",
    "        if \"table\" in variant:\n",
    "            meta[\"mod\"] = \"table\"        \n",
    "\n",
    "        print(f\"provider: {provider}, dataset: {dataset}, task: {task}, variant: {variant}, meta: {meta}\")\n",
    "        temp_path = f\"./temp/{provider}/{dataset}/{task}/{variant}\"\n",
    "        db.save_to_disk(temp_path)\n",
    "        staging_dir, job_id = manager.upload_raw_data(\n",
    "            data_file=temp_path,\n",
    "            provider=provider,\n",
    "            dataset=dataset,\n",
    "            dataset_description=\"설명을 변경해주세요.\",\n",
    "            original_source=\"링크를 입력해주세요.\",\n",
    "            overwrite=False,\n",
    "        )\n",
    "        # manager.trigger_nas_processing()\n",
    "        # manager.wait_for_job_completion(job_id, timeout=1280000)\n",
    "        # uploaded_db = Dataset.from_parquet(f\"/mnt/AI_NAS/datalake/catalog/provider={provider}/dataset={dataset}/task=raw/variant=*/data.parquet\")\n",
    "        # uploaded_db.save_to_disk(temp_path)\n",
    "        # manager.upload_task_data(\n",
    "        #     data_file=temp_path,\n",
    "        #     provider=provider,\n",
    "        #     dataset=dataset,\n",
    "        #     task=task,\n",
    "        #     variant=variant,\n",
    "        #     dataset_description=\"설명을 변경해주세요.\",\n",
    "        #     original_source=\"링크를 입력해주세요.\",\n",
    "        #     **meta,  # unpack meta dictionary\n",
    "        # )\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {parquet_path}: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "        error_list.append({\n",
    "            \"parquet_path\": parquet_path,\n",
    "            \"error\": str(e)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b888aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_dir, job_id = manager.upload_raw_data(\n",
    "    data_file=temp_path,\n",
    "    provider=provider,\n",
    "    dataset=dataset,\n",
    "    dataset_description=\"설명을 변경해주세요.\",\n",
    "    original_source=\"링크를 입력해주세요.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b984c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.show_nas_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.trigger_nas_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283a89ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.wait_for_job_completion(\"job_20250616_074217_948\", timeout=1280000, polling_interval=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f1b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.move(\"/data.parquet\", \"/mnt/AI_NAS/datalake/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376e05f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.show_nas_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0633a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.trigger_nas_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341155cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.upload_raw_data(\n",
    "    data_file=\"arrow경로\",\n",
    "    provider=\"provider_name\",\n",
    "    dataset=\"dataset_name\",\n",
    "    dataset_description=\"설명을 변경해주세요.\",\n",
    "    original_source=\"링크를 입력해주세요.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.upload_task_data(\n",
    "    data_file=parquet_path,\n",
    "    provider=provider,\n",
    "    dataset=dataset,\n",
    "    task=task,\n",
    "    variant=variant,\n",
    "    dataset_description=\"설명을 변경해주세요.\",\n",
    "    original_source=\"링크를 입력해주세요.\",\n",
    "    **meta,  # unpack meta dictionary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbd5ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da4c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = client.execute(\"\"\"\n",
    "    SELECT * FROM read_parquet('/mnt/AI_NAS/datalake/catalog/provider=*/dataset=*/task=*/variant=*/data.parquet', union_by_name=True, filename=True, hive_partitioning=True)\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05a44df",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset.from_pandas(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92ef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0638af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path에 /mnt/AI_NASd/datalake/assets 추가\n",
    "d = d.map(lambda x: {\"path\": f\"/mnt/AI_NAS/datalake/assets/{x['path']}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd3509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d의 filename이 exsts한지 확인\n",
    "def check_image_exists(row):\n",
    "    if row['path']:\n",
    "        path = row['path']\n",
    "        return os.path.exists(path)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.map(lambda x: {\"image_exists\": check_image_exists(x)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaiocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
