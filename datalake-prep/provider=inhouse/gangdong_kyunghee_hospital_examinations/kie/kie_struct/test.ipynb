{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd032265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "import re\n",
    "src = \"/home/kai/workspace/DeepDocs_Project/DataETL/source/provider=inhouse/gangdong_kyunghee_hospital/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af86fb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "examinations = glob(f\"{src}/examinations/**/*.jpg\", recursive=True)\n",
    "examination_label = glob(f\"{src}/examinations/**/*.json\", recursive=True)\n",
    "examination_jsonl = glob(f\"{src}/examinations/**/*.jsonl\", recursive=True)\n",
    "len(examinations), len(examination_label), len(examination_jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e77e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_labels = {}\n",
    "for jsonl_path in tqdm(examination_jsonl):\n",
    "    with open(jsonl_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        data = json.loads(line)\n",
    "        file_name = data[\"file_name\"]\n",
    "        ground_truth = json.loads(data[\"ground_truth\"])\n",
    "        if file_name in exam_labels:\n",
    "            print(f\"Duplicate file name found: {file_name}\")\n",
    "        exam_labels[file_name] = ground_truth\n",
    "\n",
    "exam_labels = {k: v for k, v in exam_labels.items() if v is not None}\n",
    "\n",
    "print(f\"Exam labels: {len(exam_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f91b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeated_phrase(text):\n",
    "    text = text.strip()\n",
    "    norm_text = re.sub(r'\\s+', '', text)  # 중복된 공백 제거\n",
    "    n = len(norm_text)\n",
    "    for size in range(1, n // 2 + 1):\n",
    "        phrase = norm_text[:size]\n",
    "        if phrase * (n // size) == norm_text:\n",
    "            start = 0 \n",
    "            end = 0\n",
    "            count = 0 \n",
    "            for idx, char in enumerate(text):\n",
    "                if not char.isspace():\n",
    "                    count += 1\n",
    "                if count == size:\n",
    "                    end = idx + 1\n",
    "                    break\n",
    "            return text[start:end].strip()\n",
    "    return text.strip()  # 반복 구조가 아니면 원문 그대로 반환\n",
    "\n",
    "def get_sha256(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        bytes = f.read()\n",
    "        hash = hashlib.sha256(bytes).hexdigest()\n",
    "    return hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e03a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for idx, image_path in tqdm(enumerate(examinations)):\n",
    "    file_name = os.path.basename(image_path)\n",
    "    if file_name not in exam_labels:\n",
    "        print(f\"Missing label for examination image: {file_name}\")\n",
    "        continue\n",
    "    ground_truth = exam_labels.get(file_name)\n",
    "    if ground_truth is None:\n",
    "        print(f\"Ground truth is None for examination image: {file_name}\")\n",
    "        continue\n",
    "    # Process the image as needed, e.g., save or analyze\n",
    "    img = Image.open(image_path)\n",
    "    gt = ground_truth.get(\"gt_parse\", {})\n",
    "    \n",
    "    kie_label = gt['examinations']\n",
    "    exam_label = gt['exam_label']['issuer']\n",
    "    kie_converted = {\n",
    "        'items': []\n",
    "    }\n",
    "    if exam_label.strip():\n",
    "        kie_converted['name'] = remove_repeated_phrase(exam_label)\n",
    "    for item in kie_label:\n",
    "        \n",
    "        date = item['date']\n",
    "        if not re.match(r'^\\d{4}-\\d{2}-\\d{2}$', date):\n",
    "            print(f\"Invalid date format in {file_name}: {date}\")\n",
    "        exam_infos = item.get(\"exam_info\", [])\n",
    "        item_ = {\n",
    "            \"date\": date,\n",
    "            \"info\": []\n",
    "        }\n",
    "        for exam_info_ in exam_infos:\n",
    "            info_ = {}\n",
    "            for key, value in exam_info_.items():\n",
    "                \n",
    "                if key == \"refer_val\":\n",
    "                    # 대괄호가 덜 닫혀있을경우 괄호 제거 ex) [ 2.5 -> 2.5 , [ 2.5, 3.0 ] -> [2.5, 3.0]\n",
    "                    if value.startswith('[') and not value.endswith(']'):\n",
    "                        value = value[1:].strip()\n",
    "                    if value.endswith(']') and not value.startswith('['):\n",
    "                        value = value[:-1].strip()\n",
    "                    if re.match(r'^\\d+(\\.\\d+)?\\s+\\d+(\\.\\d+)?$', value):\n",
    "                        value = value.replace(' ', '~')\n",
    "                        \n",
    "                if key == \"unit\":\n",
    "                    value = value.replace('ul', 'uL')\n",
    "                    \n",
    "                value = value.strip().replace(\"'\", '\"')\n",
    "                value = re.sub(r'\\s+', ' ', value)\n",
    "                info_[key] = value\n",
    "                \n",
    "            \n",
    "            item_['info'].append(info_)\n",
    "        kie_converted['items'].append(item_)\n",
    "    imgsha256 = get_sha256(image_path)\n",
    "    save_path = Path(f\"images/{imgsha256}.jpg\")\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(image_path, save_path)\n",
    "    records.append({\n",
    "        \"image_path\": str(save_path.relative_to(Path(save_path).parent)),\n",
    "        \"width\": img.width,\n",
    "        \"height\": img.height,\n",
    "        \"label\": json.dumps(kie_converted, ensure_ascii=False),\n",
    "    })\n",
    "df = pd.DataFrame(records)\n",
    "df.to_parquet(\"examinations.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaiocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
