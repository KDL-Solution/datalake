{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8298a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "import re\n",
    "src = \"/home/kai/workspace/DeepDocs_Project/DataETL/source/provider=inhouse/gangdong_kyunghee_hospital/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c74e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "prescriptions = glob(f\"{src}/prescriptions/**/*.jpg\", recursive=True)\n",
    "prescription_label = glob(f\"{src}/prescriptions/**/*.json\", recursive=True)\n",
    "prescription_jsonl = glob(f\"{src}/prescriptions/**/*.jsonl\", recursive=True)\n",
    "len(prescriptions), len(prescription_label), len(prescription_jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e77a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_labels = {}\n",
    "for jsonl_path in tqdm(prescription_jsonl):\n",
    "    with open(jsonl_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        data = json.loads(line)\n",
    "        file_name = data[\"file_name\"]\n",
    "        ground_truth = json.loads(data[\"ground_truth\"])\n",
    "        if file_name in pres_labels:\n",
    "            print(f\"Duplicate file name found: {file_name}\")\n",
    "        pres_labels[file_name] = ground_truth\n",
    "        \n",
    "pres_labels = {k: v for k, v in pres_labels.items() if v is not None}\n",
    "print(f\"Prescription labels: {len(pres_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bbeca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeated_phrase(text):\n",
    "    text = text.strip()\n",
    "    norm_text = re.sub(r'\\s+', '', text)  # 중복된 공백 제거\n",
    "    n = len(norm_text)\n",
    "    for size in range(1, n // 2 + 1):\n",
    "        phrase = norm_text[:size]\n",
    "        if phrase * (n // size) == norm_text:\n",
    "            start = 0 \n",
    "            end = 0\n",
    "            count = 0 \n",
    "            for idx, char in enumerate(text):\n",
    "                if not char.isspace():\n",
    "                    count += 1\n",
    "                if count == size:\n",
    "                    end = idx + 1\n",
    "                    break\n",
    "            return text[start:end].strip()\n",
    "    return text.strip()  # 반복 구조가 아니면 원문 그대로 반환\n",
    "\n",
    "def get_sha256(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        bytes = f.read()\n",
    "        hash = hashlib.sha256(bytes).hexdigest()\n",
    "    return hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d717b323",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for idx, image_path in tqdm(enumerate(prescriptions)):\n",
    "    file_name = os.path.basename(image_path)\n",
    "    if file_name not in pres_labels:\n",
    "        print(f\"Missing label for examination image: {file_name}\")\n",
    "        continue\n",
    "    ground_truth = pres_labels.get(file_name)\n",
    "    if ground_truth is None:\n",
    "        print(f\"Ground truth is None for examination image: {file_name}\")\n",
    "        continue\n",
    "    # Process the image as needed, e.g., save or analyze\n",
    "    img = Image.open(image_path)\n",
    "    gt = ground_truth.get(\"gt_parse\", {})\n",
    "    \n",
    "    kie_label = gt['prescriptions']\n",
    "    date = gt['date']\n",
    "    issuer_label = gt['issuer']\n",
    "    if not re.match(r'^\\d{4}-\\d{2}-\\d{2}$', date):\n",
    "        print(f\"Invalid date format in {file_name}: {date}\")\n",
    "    kie_converted = {\n",
    "        'date': date,\n",
    "        'items': []\n",
    "    }\n",
    "    if issuer_label.strip():\n",
    "        kie_converted['name'] = remove_repeated_phrase(issuer_label)\n",
    "    for item in kie_label:\n",
    "        info_ = {}\n",
    "            \n",
    "        for key, value in item.items():\n",
    "            if key in ['p_days', 'dosage', 'times_pd']:\n",
    "                # digit이 아닐떄 pirnt\n",
    "                if not re.match(r'^\\d+(\\.\\d+)?$', str(value)):\n",
    "                    value = value.strip().replace(\" \",\"\")\n",
    "                value = str(value)\n",
    "            value = value.strip().replace(\"'\", '\"')\n",
    "            value = re.sub(r'\\s+', ' ', value)\n",
    "            info_[key] = value\n",
    "        kie_converted['items'].append(info_)\n",
    "    \n",
    "    imgsha256 = get_sha256(image_path)\n",
    "    save_path = Path(f\"images/{imgsha256}.jpg\")\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(image_path, save_path)\n",
    "    records.append({\n",
    "        \"image_path\": str(save_path.relative_to(Path(save_path).parent)),\n",
    "        \"width\": img.width,\n",
    "        \"height\": img.height,\n",
    "        \"label\": json.dumps(kie_converted, ensure_ascii=False),\n",
    "    })\n",
    "df = pd.DataFrame(records)\n",
    "df.to_parquet(\"prescriptions.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
